{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 06:52:02,257\tWARNING utils.py:575 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.\n",
      "2024-05-17 06:52:04,397\tWARNING services.py:1996 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-05-17 06:52:04,480\tINFO worker.py:1715 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "sys.path.append(\"/home/local/kyeonghunjeong_920205/nipa_bu/COVID19/3.analysis/9.MIL/scAMIL_cell/scMILD\")\n",
    "from utils import *\n",
    "from dataset import *\n",
    "from model import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "import modin.pandas as pd\n",
    "import ray\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/local/kyeonghunjeong_920205/nipa_bu/COVID19/3.analysis/9.MIL/scAMIL_cell/scMILD/downstream/NS'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path=\"NS\"\n",
    "base_path = f\"../../data/{dir_path}/\"\n",
    "target_dir = f'{base_path}/AE/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using device: cuda:4\n"
     ]
    }
   ],
   "source": [
    "device_num = 4\n",
    "device = torch.device(f'cuda:{device_num}' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"INFO: Using device: {}\".format(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: When using a pre-initialized Ray cluster, please ensure that the runtime env sets environment variable __MODIN_AUTOIMPORT_PANDAS__ to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32588, 32871)\n",
      "(26947, 32871)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Complete!\n",
      "(26947, 27765)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dat = sparse.load_npz(os.path.join(base_path, \"RawCounts.npz\"))\n",
    "genes = open(os.path.join(base_path, \"genes.txt\")).read().strip().split(\"\\n\")\n",
    "barcodes = open(os.path.join(base_path, \"barcodes.txt\")).read().strip().split(\"\\n\")\n",
    "meta = pd.read_csv(os.path.join(base_path, \"20210701_NasalSwab_MetaData.txt\"), sep=\"\\t\").drop(axis=0,index=0).reset_index(drop=True)\n",
    "\n",
    "cell_types = pd.read_csv(os.path.join(base_path, \"20210220_NasalSwab_UMAP.txt\"), sep=\"\\t\").drop(axis=0,index=0).reset_index(drop=True)[\"Category\"]\n",
    "ct_id = sorted(set(cell_types))\n",
    "mapping_ct = {c:idx for idx, c in enumerate(ct_id)}\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "ct = []\n",
    "\n",
    "adata = sc.AnnData(dat.astype(np.float32), obs=barcodes, var=genes)\n",
    "\n",
    "print(adata.shape)\n",
    "barcodes = adata.obs[0].tolist()\n",
    "\n",
    "meta_subset = meta[meta['NAME'].isin(barcodes)]\n",
    "meta_subset.set_index('NAME', inplace=True)\n",
    "meta_subset = meta_subset.reindex(adata.obs[0])\n",
    "\n",
    "adata.obs['ind_cov'] = meta_subset['donor_id'].values\n",
    "adata.obs['ct_cov'] = meta_subset['Coarse_Cell_Annotations'].values\n",
    "adata.obs['disease_cov'] = meta_subset['disease__ontology_label'].values\n",
    "\n",
    "adata = adata[adata.obs['disease_cov'].isin(['normal', 'COVID-19'])]\n",
    "print(adata.shape)\n",
    "\n",
    "sc.pp.filter_genes(adata, min_cells=5)\n",
    "print(\"Preprocessing Complete!\")\n",
    "print(adata.shape)\n",
    "mapping = {'normal': 0, 'COVID-19': 1}\n",
    "adata.obs['disease_numeric'] = adata.obs['disease_cov'].map(mapping)\n",
    "adata.obs['sample_id_numeric'], _ = pd.factorize(adata.obs['ind_cov'])\n",
    "sample_labels = adata.obs[['disease_numeric', 'sample_id_numeric']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# saved_model_path = '../../results/model_NS_ae_ed128_md64_lr0.0001_500_0.3_3_45_reported'\n",
    "saved_model_path = '../../results/model_NS_ae_ed128_md64_lr0.0001_500_0.3_500_45_baseline'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "for exp in range(1,9):\n",
    "    print(f'Experiment {exp}')\n",
    "    train_dataset, val_dataset, test_dataset, label_encoder = load_dataset_and_preprocessors(base_path, exp, device)\n",
    "    instance_test_dataset = update_instance_labels_with_bag_labels(test_dataset, device)\n",
    "    model_teacher = torch.load(f'{saved_model_path}/model_teacher_exp{exp}.pt')\n",
    "    model_encoder = torch.load(f'{saved_model_path}/model_encoder_exp{exp}.pt')\n",
    "    \n",
    "    \n",
    "    model_encoder.to(device)\n",
    "    model_teacher.to(device)\n",
    "\n",
    "    model_encoder.eval()\n",
    "    model_teacher.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model_encoder(instance_test_dataset.data.clone().detach().float().to(device))[:, :model_teacher.input_dims].detach().requires_grad_(False)\n",
    "        cell_score_teacher = model_teacher.attention_module(features).squeeze(0)\n",
    "    features_np = features.cpu().detach().numpy()\n",
    "    cell_score_teacher_np = cell_score_teacher.cpu().detach().numpy()\n",
    "\n",
    "    df = pd.DataFrame(features_np, columns = [f'feature_{i}' for i in range(features_np.shape[1])])\n",
    "\n",
    "    df['cell_type']= label_encoder.inverse_transform(instance_test_dataset.instance_labels.cpu().detach().numpy())\n",
    "    df['cell_score'] = cell_score_teacher_np\n",
    "    df['bag_labels'] = instance_test_dataset.bag_labels.cpu().detach().numpy()\n",
    "    df['instance_labels'] = instance_test_dataset.instance_labels.cpu().detach().numpy()\n",
    "    df['cell_score_minmax']= (df['cell_score'].values - min(df['cell_score'].values)) / (max(df['cell_score'].values)- min(df['cell_score'].values))\n",
    "\n",
    "    df.to_csv(f'cell_score_{exp}_baseline.csv', index=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
