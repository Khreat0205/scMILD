{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "sys.path.append(\"/home/local/kyeonghunjeong_920205/nipa_bu/COVID19/3.analysis/9.MIL/scAMIL_cell/scMILD\")\n",
    "from src.utils import *\n",
    "from src.dataset import InstanceDataset\n",
    "from src.model import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "import modin.pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path=\"NS\"\n",
    "base_path = f\"../../data/{dir_path}/\"\n",
    "target_dir = f'{base_path}/AE/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device_num = 0\n",
    "device = torch.device(f'cuda:{device_num}' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"INFO: Using device: {}\".format(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_cell_scores(saved_model_path, exp, test_dataset, label_encoder, device, suffix=None):\n",
    "    instance_test_dataset = update_instance_labels_with_bag_labels(test_dataset, device)\n",
    "\n",
    "    model_teacher = torch.load(f'{saved_model_path}/model_teacher_exp{exp}.pt', map_location=device)\n",
    "    model_encoder = torch.load(f'{saved_model_path}/model_encoder_exp{exp}.pt', map_location=device)\n",
    "    model_student = torch.load(f'{saved_model_path}/model_student_exp{exp}.pt', map_location=device)\n",
    "\n",
    "    model_encoder.eval()\n",
    "    model_student.eval()\n",
    "    model_teacher.eval()\n",
    "    with torch.no_grad():\n",
    "        features = model_encoder(instance_test_dataset.data.clone().detach().float().to(device))[:, :model_teacher.input_dims].detach().requires_grad_(False)\n",
    "        cell_score_teacher = model_teacher.attention_module(features).squeeze(0)\n",
    "    \n",
    "    features_np = features.cpu().detach().numpy()\n",
    "    cell_score_teacher_np = cell_score_teacher.cpu().detach().numpy()\n",
    "\n",
    "    df = pd.DataFrame(features_np, columns=[f'feature_{i}' for i in range(features_np.shape[1])])\n",
    "    df['cell_type'] = label_encoder.inverse_transform(instance_test_dataset.instance_labels.cpu().detach().numpy())\n",
    "    df['cell_score'] = cell_score_teacher_np\n",
    "    df['bag_labels'] = instance_test_dataset.bag_labels.cpu().detach().numpy()\n",
    "    df['instance_labels'] = instance_test_dataset.instance_labels.cpu().detach().numpy()\n",
    "    df['cell_score_minmax'] = (df['cell_score'].values - min(df['cell_score'].values)) / (max(df['cell_score'].values) - min(df['cell_score'].values))\n",
    "    if suffix is not None: \n",
    "        df.to_csv(f'cell_score_{exp}_{suffix}.csv', index=False)    \n",
    "    else: \n",
    "        df.to_csv(f'cell_score_{exp}.csv', index=False)\n",
    "        \n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Ray execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    import ray\n",
      "    ray.init()\n",
      "\n",
      "UserWarning: The size of /dev/shm is too small (67108864 bytes). The required size at least half of RAM (540996296704 bytes). Please, delete files in /dev/shm or increase size of /dev/shm with --shm-size in Docker. Also, you can can override the memory size for each Ray worker (in bytes) to the MODIN_MEMORY environment variable.\n",
      "2024-06-13 11:18:42,377\tWARNING services.py:1996 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-06-13 11:18:42,784\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** SIGTERM received at time=1718279657 on cpu 10 ***\n",
      "PC: @     0x7f10460a068e  (unknown)  epoll_wait\n",
      "    @     0x7f10462e1420  (unknown)  (unknown)\n",
      "[2024-06-13 11:54:17,787 E 837338 837338] logging.cc:361: *** SIGTERM received at time=1718279657 on cpu 10 ***\n",
      "[2024-06-13 11:54:17,787 E 837338 837338] logging.cc:361: PC: @     0x7f10460a068e  (unknown)  epoll_wait\n",
      "[2024-06-13 11:54:17,787 E 837338 837338] logging.cc:361:     @     0x7f10462e1420  (unknown)  (unknown)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "\n",
    "saved_model_paths = [\n",
    "        # '/home/local/kyeonghunjeong_920205/nipa_bu/COVID19/3.analysis/9.MIL/scAMIL_cell/scMILD/results/NS_model_ae_ed128_md16_lr0.0001_100_0.3_1_10__0607_433_op_gmm_device4_only_using_loss_switch',\n",
    "        # '/home/local/kyeonghunjeong_920205/nipa_bu/COVID19/3.analysis/9.MIL/scAMIL_cell/scMILD/results/NS_baseline_model_ae_ed128_md16_lr0.0001_100_0.3_1_10__0613',\n",
    "        '/home/local/kyeonghunjeong_920205/nipa_bu/COVID19/3.analysis/9.MIL/scAMIL_cell/scMILD/results/NS_not_op_model_ae_ed128_md16_lr0.0001_100_0.3_1_10__0613'\n",
    "    ]\n",
    "\n",
    "for saved_model_path in saved_model_paths:\n",
    "    for exp in range(1, 9):\n",
    "        print(f'Experiment {exp}')\n",
    "        _, _, test_dataset, label_encoder = load_dataset_and_preprocessors(base_path, exp, device)\n",
    "        # suffix = 'baseline' if 'baseline' in saved_model_path else None\n",
    "        suffix = 'not_op' if 'not_op' in saved_model_path else None\n",
    "        save_cell_scores(saved_model_path, exp, test_dataset, label_encoder, device, suffix)\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: When using a pre-initialized Ray cluster, please ensure that the runtime env sets environment variable __MODIN_AUTOIMPORT_PANDAS__ to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32588, 32871)\n",
      "(26947, 32871)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Complete!\n",
      "(26947, 27765)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dat = sparse.load_npz(os.path.join(base_path, \"RawCounts.npz\"))\n",
    "genes = open(os.path.join(base_path, \"genes.txt\")).read().strip().split(\"\\n\")\n",
    "barcodes = open(os.path.join(base_path, \"barcodes.txt\")).read().strip().split(\"\\n\")\n",
    "meta = pd.read_csv(os.path.join(base_path, \"20210701_NasalSwab_MetaData.txt\"), sep=\"\\t\").drop(axis=0,index=0).reset_index(drop=True)\n",
    "\n",
    "cell_types = pd.read_csv(os.path.join(base_path, \"20210220_NasalSwab_UMAP.txt\"), sep=\"\\t\").drop(axis=0,index=0).reset_index(drop=True)[\"Category\"]\n",
    "ct_id = sorted(set(cell_types))\n",
    "mapping_ct = {c:idx for idx, c in enumerate(ct_id)}\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "ct = []\n",
    "\n",
    "adata = sc.AnnData(dat.astype(np.float32), obs=barcodes, var=genes)\n",
    "\n",
    "print(adata.shape)\n",
    "barcodes = adata.obs[0].tolist()\n",
    "\n",
    "meta_subset = meta[meta['NAME'].isin(barcodes)]\n",
    "meta_subset.set_index('NAME', inplace=True)\n",
    "meta_subset = meta_subset.reindex(adata.obs[0])\n",
    "\n",
    "adata.obs['ind_cov'] = meta_subset['donor_id'].values\n",
    "adata.obs['ct_cov'] = meta_subset['Coarse_Cell_Annotations'].values\n",
    "adata.obs['disease_cov'] = meta_subset['disease__ontology_label'].values\n",
    "\n",
    "adata = adata[adata.obs['disease_cov'].isin(['normal', 'COVID-19'])]\n",
    "print(adata.shape)\n",
    "\n",
    "sc.pp.filter_genes(adata, min_cells=5)\n",
    "print(\"Preprocessing Complete!\")\n",
    "print(adata.shape)\n",
    "mapping = {'normal': 0, 'COVID-19': 1}\n",
    "adata.obs['disease_numeric'] = adata.obs['disease_cov'].map(mapping)\n",
    "adata.obs['sample_id_numeric'], _ = pd.factorize(adata.obs['ind_cov'])\n",
    "sample_labels = adata.obs[['disease_numeric', 'sample_id_numeric']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "saved_model_path = '../../results/model_NS_ae_ed128_md64_lr0.0001_500_0.3_3_45_reported'\n",
    "saved_baseline_path = '../../results/model_NS_ae_ed128_md64_lr0.0001_500_0.3_3_45_baseline'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n"
     ]
    }
   ],
   "source": [
    "for exp in range(1,9):\n",
    "    print(f'Experiment {exp}')\n",
    "    train_dataset, val_dataset, test_dataset, label_encoder = load_dataset_and_preprocessors(base_path, exp, device)\n",
    "    instance_test_dataset = update_instance_labels_with_bag_labels(test_dataset, device)\n",
    "    model_teacher = torch.load(f'{saved_model_path}/model_teacher_exp{exp}.pt')\n",
    "    model_encoder = torch.load(f'{saved_model_path}/model_encoder_exp{exp}.pt')\n",
    "    \n",
    "    baseline_teacher = torch.load(f'{saved_baseline_path}/model_teacher_exp{exp}.pt')\n",
    "    baseline_encoder = torch.load(f'{saved_baseline_path}/model_encoder_exp{exp}.pt')\n",
    "\n",
    "    model_encoder.to(device)\n",
    "    model_teacher.to(device)\n",
    "\n",
    "    model_encoder.eval()\n",
    "    model_teacher.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model_encoder(instance_test_dataset.data.clone().detach().float().to(device))[:, :model_teacher.input_dims].detach().requires_grad_(False)\n",
    "        cell_score_teacher = model_teacher.attention_module(features).squeeze(0)\n",
    "    features_np = features.cpu().detach().numpy()\n",
    "    cell_score_teacher_np = cell_score_teacher.cpu().detach().numpy()\n",
    "\n",
    "    df = pd.DataFrame(features_np, columns = [f'feature_{i}' for i in range(features_np.shape[1])])\n",
    "\n",
    "    df['cell_type']= label_encoder.inverse_transform(instance_test_dataset.instance_labels.cpu().detach().numpy())\n",
    "    df['cell_score'] = cell_score_teacher_np\n",
    "    df['bag_labels'] = instance_test_dataset.bag_labels.cpu().detach().numpy()\n",
    "    df['instance_labels'] = instance_test_dataset.instance_labels.cpu().detach().numpy()\n",
    "    df['cell_score_minmax']= (df['cell_score'].values - min(df['cell_score'].values)) / (max(df['cell_score'].values)- min(df['cell_score'].values))\n",
    "\n",
    "    df.to_csv(f'cell_score_{exp}.csv', index=False)\n",
    "    split_ratio = [0.5, 0.25, 0.25]\n",
    "    train_val_set, test_set = train_test_split(sample_labels, test_size=split_ratio[2], random_state=exp, stratify=sample_labels['disease_numeric'])\n",
    "    train_set, val_set = train_test_split(train_val_set, test_size=split_ratio[1] / (1 - split_ratio[2]), random_state=exp,stratify=train_val_set['disease_numeric'])\n",
    "    test_data = adata[adata.obs['sample_id_numeric'].isin(test_set['sample_id_numeric'])]\n",
    "    \n",
    "\n",
    "    test_data.obs.rename(columns={0: 'cell.names'}, inplace=True)\n",
    "    test_data.var.rename(columns={0: 'gene.names'}, inplace=True)\n",
    "    test_data.obs.columns = [sub.replace('(', '') for sub in test_data.obs.columns]\n",
    "    test_data.obs.columns = [sub.replace(')', '') for sub in test_data.obs.columns]\n",
    "    test_data.obs.columns = [sub.replace('/', '') for sub in test_data.obs.columns]\n",
    "    test_data.obs.columns = [sub.replace('=', '.') for sub in test_data.obs.columns]\n",
    "    test_data.obs.columns = [sub.replace(' ', '_') for sub in test_data.obs.columns]\n",
    "    test_data.obs.columns = [sub.replace('-', '_') for sub in test_data.obs.columns]\n",
    "\n",
    "    test_data.obs.index = test_data.obs['cell.names']\n",
    "    test_data.var.index = test_data.var['gene.names']\n",
    "    test_data.write(filename=f\"anndata_{exp}.h5ad\")\n",
    "    test_data.obs.to_csv(f\"obs_{exp}.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_baseline_path = '../../results/model_NS_ae_ed128_md64_lr0.0001_500_0.3_3_45_reported'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../results/model_NS_ae_ed128_md64_lr0.0001_500_0.3_3_45_reported\n"
     ]
    }
   ],
   "source": [
    "print(saved_model_path)\n",
    "\n",
    "adata.obs.rename(columns={0: 'cell.names'}, inplace=True)\n",
    "adata.var.rename(columns={0: 'gene.names'}, inplace=True)\n",
    "adata.obs.columns = [sub.replace('(', '') for sub in adata.obs.columns]\n",
    "adata.obs.columns = [sub.replace(')', '') for sub in adata.obs.columns]\n",
    "adata.obs.columns = [sub.replace('/', '') for sub in adata.obs.columns]\n",
    "adata.obs.columns = [sub.replace('=', '.') for sub in adata.obs.columns]\n",
    "adata.obs.columns = [sub.replace(' ', '_') for sub in adata.obs.columns]\n",
    "adata.obs.columns = [sub.replace('-', '_') for sub in adata.obs.columns]\n",
    "\n",
    "adata.obs.index = adata.obs['cell.names']\n",
    "adata.var.index = adata.var['gene.names']\n",
    "adata.write(filename=f\"whole_anndata.h5ad\")\n",
    "adata.obs.to_csv(f\"whole_obs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
