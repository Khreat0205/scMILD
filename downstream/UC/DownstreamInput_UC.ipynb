{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 11:19:24,125\tWARNING utils.py:575 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.\n",
      "2024-06-13 11:19:26,897\tWARNING services.py:1996 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-06-13 11:19:27,156\tINFO worker.py:1715 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "sys.path.append(\"/home/local/kyeonghunjeong_920205/nipa_bu/COVID19/3.analysis/9.MIL/scAMIL_cell/scMILD\")\n",
    "import argparse\n",
    "import json\n",
    "import random\n",
    "from src.utils import *\n",
    "from src.dataset import *\n",
    "from src.model import *\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "import modin.pandas as pd\n",
    "import ray\n",
    "ray.init()\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_recall_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = f'UC/'\n",
    "base_path = f'../../data/{dir_path}'\n",
    "target_dir = f'{base_path}/AE/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31872, 2000)\n",
      "(18725, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n"
     ]
    }
   ],
   "source": [
    "adata = sc.read_h5ad(f'{base_path}/Fib.h5ad')\n",
    "print(adata.shape)\n",
    "adata = adata[adata.obs['Health'].isin(('Healthy','Inflamed'))]\n",
    "mapping = {'Healthy': 0, 'Inflamed': 1}\n",
    "adata.obs['disease_numeric'] = adata.obs['Health'].map(mapping)\n",
    "adata.obs['sample_id_numeric'], _ = pd.factorize(adata.obs['Subject'])\n",
    "print(adata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using device: cuda:6\n"
     ]
    }
   ],
   "source": [
    "device_num = 6\n",
    "device = torch.device(f'cuda:{device_num}' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"INFO: Using device: {}\".format(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_cell_scores(saved_model_path, exp, test_dataset, label_encoder, device, suffix=None):\n",
    "    instance_test_dataset = update_instance_labels_with_bag_labels(test_dataset, device)\n",
    "\n",
    "    model_teacher = torch.load(f'{saved_model_path}/model_teacher_exp{exp}.pt', map_location=device)\n",
    "    model_encoder = torch.load(f'{saved_model_path}/model_encoder_exp{exp}.pt', map_location=device)\n",
    "    model_student = torch.load(f'{saved_model_path}/model_student_exp{exp}.pt', map_location=device)\n",
    "\n",
    "    model_encoder.eval()\n",
    "    model_student.eval()\n",
    "    model_teacher.eval()\n",
    "    with torch.no_grad():\n",
    "        features = model_encoder(instance_test_dataset.data.clone().detach().float().to(device))[:, :model_teacher.input_dims].detach().requires_grad_(False)\n",
    "        cell_score_teacher = model_teacher.attention_module(features).squeeze(0)\n",
    "    \n",
    "    features_np = features.cpu().detach().numpy()\n",
    "    cell_score_teacher_np = cell_score_teacher.cpu().detach().numpy()\n",
    "\n",
    "    df = pd.DataFrame(features_np, columns=[f'feature_{i}' for i in range(features_np.shape[1])])\n",
    "    df['cell_type'] = label_encoder.inverse_transform(instance_test_dataset.instance_labels.cpu().detach().numpy())\n",
    "    df['cell_score'] = cell_score_teacher_np\n",
    "    df['bag_labels'] = instance_test_dataset.bag_labels.cpu().detach().numpy()\n",
    "    df['instance_labels'] = instance_test_dataset.instance_labels.cpu().detach().numpy()\n",
    "    df['cell_score_minmax'] = (df['cell_score'].values - min(df['cell_score'].values)) / (max(df['cell_score'].values) - min(df['cell_score'].values))\n",
    "    if suffix is not None: \n",
    "        df.to_csv(f'cell_score_{exp}_{suffix}.csv', index=False)    \n",
    "    else: \n",
    "        df.to_csv(f'cell_score_{exp}.csv', index=False)\n",
    "        \n",
    "    return 0\n",
    "\n",
    "def save_test_data(exp, sample_labels, adata):\n",
    "    split_ratio = [0.5, 0.25, 0.25]\n",
    "    train_val_set, test_set = train_test_split(sample_labels, test_size=split_ratio[2], random_state=exp, stratify=sample_labels['disease_numeric'])\n",
    "    train_set, val_set = train_test_split(train_val_set, test_size=split_ratio[1] / (1 - split_ratio[2]), random_state=exp, stratify=train_val_set['disease_numeric'])\n",
    "    test_set.to_csv(f\"test_set_barcodes_{exp}.csv\")\n",
    "    test_data = adata[adata.obs['sample_id_numeric'].isin(test_set['sample_id_numeric'])]    \n",
    "    test_data.obs.to_csv(f\"obs_{exp}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: When using a pre-initialized Ray cluster, please ensure that the runtime env sets environment variable __MODIN_AUTOIMPORT_PANDAS__ to 1\n",
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** SIGTERM received at time=1718279921 on cpu 54 ***\n",
      "PC: @     0x7fe48bfbc68e  (unknown)  epoll_wait\n",
      "    @     0x7fe48c1fd420  (unknown)  (unknown)\n",
      "[2024-06-13 11:58:41,112 E 875141 875141] logging.cc:361: *** SIGTERM received at time=1718279921 on cpu 54 ***\n",
      "[2024-06-13 11:58:41,112 E 875141 875141] logging.cc:361: PC: @     0x7fe48bfbc68e  (unknown)  epoll_wait\n",
      "[2024-06-13 11:58:41,112 E 875141 875141] logging.cc:361:     @     0x7fe48c1fd420  (unknown)  (unknown)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "saved_model_paths = [\n",
    "        '../../results/model_UC_ae_ed128_md64_lr0.001_100_0.3_3_15',\n",
    "        '../../results/model_UC_ae_ed128_md64_lr0.001_100_0.3_100_15_baseline',\n",
    "    ]\n",
    "\n",
    "saved_model_paths = [\n",
    "        #'/home/local/kyeonghunjeong_920205/nipa_bu/COVID19/3.analysis/9.MIL/scAMIL_cell/scMILD/results/UC_hyper2_model_ae_ed128_md16_lr0.0001_100_0.1_1_15__0613',\n",
    "       # '/home/local/kyeonghunjeong_920205/nipa_bu/COVID19/3.analysis/9.MIL/scAMIL_cell/scMILD/results/UC_hyper2_baseline_model_ae_ed128_md16_lr0.0001_100_0.1_1_15__0613',\n",
    "       '/home/local/kyeonghunjeong_920205/nipa_bu/COVID19/3.analysis/9.MIL/scAMIL_cell/scMILD/results/UC_hyper2_not_op_model_ae_ed128_md16_lr0.0001_100_0.1_1_15__0613'\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "for saved_model_path in saved_model_paths:\n",
    "    for exp in range(1, 9):\n",
    "        print(f'Experiment {exp}')\n",
    "        _, _, test_dataset, label_encoder = load_dataset_and_preprocessors(base_path, exp, device)\n",
    "        # suffix = 'baseline' if 'baseline' in saved_model_path else None\n",
    "        suffix = 'not_op' if 'not_op' in saved_model_path else None\n",
    "        save_cell_scores(saved_model_path, exp, test_dataset, label_encoder, device, suffix)\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.to_csv(f\"{saved_model_path}/meta.csv\")\n",
    "adata.write(filename=f\"{saved_model_path}/anndata_proc.h5ad\")\n",
    "sample_labels = adata.obs[['disease_numeric', 'sample_id_numeric']].drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
